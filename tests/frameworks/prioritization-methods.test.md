# Prioritization Methods Framework Test

## Test Input 1: Feature Backlog Prioritization Using RICE
```
Context: 15 potential features in backlog, need to choose top 5
Data available: User analytics, customer feedback, engineering estimates
Team: 6 engineers, need 3-month sprint planning
Goal: Systematic scoring to defend priority decisions
```

## Expected Output Validation:
- [ ] Applies RICE framework correctly (Reach × Impact × Confidence ÷ Effort)
- [ ] Uses consistent scoring methodology across all features
- [ ] Documents scoring rationale for transparency
- [ ] Identifies quick wins vs. major projects
- [ ] Balances data-driven scores with strategic fit
- [ ] Creates defendable priority ranking

## Test Input 2: Strategic Initiative Prioritization Using ICE
```
Context: Limited data available, need rapid prioritization
Options: 8 strategic initiatives competing for resources
Timeline: Decision needed within 1 week
Stakeholders: Cross-functional team with varying priorities
```

## Expected Output Validation:
- [ ] Uses ICE framework for quick assessment
- [ ] Scores consistently across team members
- [ ] Identifies highest-impact, lowest-effort opportunities
- [ ] Addresses confidence levels and uncertainty
- [ ] Enables rapid decision-making process
- [ ] Documents assumptions for future validation

## Test Input 3: User Feature Requests Using Kano Model
```
Context: Customer advisory board requesting multiple features
Challenge: Understanding satisfaction vs. investment trade-offs
Goal: Categorize features by user satisfaction impact
Resources: Need to choose 3 of 10 requested features
```

## Expected Output Validation:
- [ ] Correctly applies Kano categories (Basic/Performance/Excitement/Indifferent)
- [ ] Distinguishes must-have from nice-to-have features
- [ ] Identifies delight opportunities and differentiation
- [ ] Balances customer requests with strategic direction
- [ ] Plans feature delivery sequence based on categories
- [ ] Explains prioritization logic to stakeholders

## Edge Cases:
- **Stakeholder disagreement**: Framework provides objective discussion basis
- **Limited data**: Adapts methodology to available information
- **Competing metrics**: Helps balance different success criteria

## Success Criteria:
- Priority decisions can be explained and defended
- Team alignment on scoring methodology and results
- Regular score updates based on new data and learning
- Clear connection between scores and resource allocation