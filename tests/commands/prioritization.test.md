# Prioritization Command Test

## Test Input 1: Feature Backlog Scoring
```
/prioritization
Context: 12 features in backlog, need to select top 5 for next quarter
Method: RICE framework preferred
Data: User analytics available, engineering estimates complete
Goal: Defendable priority ranking for stakeholder review
```

## Expected Output Validation:
- [ ] Applies appropriate prioritization framework systematically
- [ ] Consistent scoring methodology across all items
- [ ] Documents scoring rationale and assumptions
- [ ] Identifies quick wins and major projects
- [ ] Provides clear priority ranking with scores
- [ ] Enables data-driven priority discussions

## Test Input 2: Strategic Initiative Ranking
```
/prioritization
Context: 6 strategic initiatives competing for engineering resources
Timeline: Rapid prioritization needed for quarterly planning
Data: Limited quantitative data, mostly strategic assessment
Framework: ICE scoring for quick evaluation
```

## Expected Output Validation:
- [ ] Uses framework appropriate for available data
- [ ] Enables rapid but systematic evaluation
- [ ] Scores initiatives on impact, confidence, ease
- [ ] Identifies highest-value opportunities
- [ ] Documents uncertainty and assumptions
- [ ] Facilitates team alignment on priorities

## Test Input 3: Customer Request Prioritization
```
/prioritization
Context: Enterprise customer advisory board submitted 8 feature requests
Challenge: Balance customer requests with product strategy
Method: Kano model to understand satisfaction impact
Goal: Communicate prioritization logic to customers
```

## Expected Output Validation:
- [ ] Applies Kano categories appropriately
- [ ] Distinguishes basic needs from excitement factors
- [ ] Balances customer input with strategic direction
- [ ] Provides rationale for prioritization decisions
- [ ] Enables customer communication and expectation setting
- [ ] Plans delivery sequence based on satisfaction impact